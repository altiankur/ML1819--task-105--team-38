{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a number for the algorithms: \n",
      "1 - for logistic regression\n",
      "2 - for naive bayes classification\n",
      "3 or any other number - for random forest classifier\n",
      "2\n",
      "(30162,)\n",
      "(30162, 96)\n",
      "naive bayes\n",
      "For noise level 0.00 %: \n",
      "accuracy = 0.76\n",
      "recall = 0.02\n",
      "precision = 1.00\n",
      "f1 = 0.04\n",
      "(30162,)\n",
      "(30162, 96)\n",
      "naive bayes\n",
      "For noise level 10.00 %: \n",
      "accuracy = 0.76\n",
      "recall = 0.02\n",
      "precision = 1.00\n",
      "f1 = 0.04\n",
      "(30162,)\n",
      "(30162, 96)\n",
      "naive bayes\n",
      "For noise level 30.00 %: \n",
      "accuracy = 0.76\n",
      "recall = 0.02\n",
      "precision = 1.00\n",
      "f1 = 0.04\n",
      "(30162,)\n",
      "(30162, 96)\n",
      "naive bayes\n",
      "For noise level 50.00 %: \n",
      "accuracy = 0.76\n",
      "recall = 0.02\n",
      "precision = 1.00\n",
      "f1 = 0.04\n",
      "(30162,)\n",
      "(30162, 96)\n",
      "naive bayes\n",
      "For noise level 70.00 %: \n",
      "accuracy = 0.75\n",
      "recall = 0.02\n",
      "precision = 1.00\n",
      "f1 = 0.04\n",
      "(30162,)\n",
      "(30162, 96)\n",
      "naive bayes\n",
      "For noise level 90.00 %: \n",
      "accuracy = 0.75\n",
      "recall = 0.02\n",
      "precision = 1.00\n",
      "f1 = 0.04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import numpy.random as nr\n",
    "import random\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from random import randint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#read data\n",
    "data1 = pd.read_csv('ml_data-2.csv')\n",
    "#print(data.columns)\n",
    "data1 = data1.replace('[?]', np.nan, regex = True)\n",
    "#print(data1.isnull().sum())\n",
    "data1.dropna(inplace = True)\n",
    "#print(data1.isnull().sum())\n",
    "num_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "cat_cols = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
    "num_Features1 = np.array(data1[['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']])\n",
    "cat_Features1 = np.array(data1[['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']])\n",
    "labels1 = np.array(data1[['salary']])\n",
    "#print(num_Features1, cat_Features1, labels1)\n",
    "\n",
    "\n",
    "def modify_dataset(data):\n",
    "    data1=data\n",
    "    data1[['age','education-num','capital-gain','capital-loss','hours-per-week']] = StandardScaler().fit_transform(data1[['age','education-num','capital-gain','capital-loss','hours-per-week']])\n",
    "    #data1= data1.replace('[?]', np.nan, regex=True)\n",
    "    data1['sex']= data1['sex'].replace('Male', 1, regex=True)\n",
    "    data1['sex']= data1['sex'].replace('Female', 0, regex=True)\n",
    "    #data1.dropna(inplace=True)\n",
    "    dummies1=pd.get_dummies(data1.workclass)\n",
    "    dummies2=pd.get_dummies(data1.education)\n",
    "    dummies3=pd.get_dummies(data1.marital_status)\n",
    "    dummies4=pd.get_dummies(data1.occupation)\n",
    "    dummies5=pd.get_dummies(data1.relationship)\n",
    "    dummies6=pd.get_dummies(data1.race)\n",
    "    dummies7=pd.get_dummies(data1.native_country)\n",
    "    merged=pd.concat([data1,dummies1,dummies2,dummies3,dummies4,dummies5,dummies6,dummies7],axis=1)\n",
    "    merged=merged.drop(['workclass', ' Without-pay', 'education', '9th', 'marital_status', ' Divorced', 'occupation', ' Other-service' ,'relationship', ' Not-in-family', 'race', ' Black', 'native_country', ' France'],axis=1)\n",
    "    new=merged\n",
    "    return new\n",
    "\n",
    "\n",
    "\n",
    "def intr_noise_and_preprocess(num_Features, cat_Features, labels, frac):\n",
    "    nr.seed(1234)\n",
    "    index = range(num_Features.shape[0])\n",
    "    #print(Features.shape[0])\n",
    "    index = random.sample(range(num_Features.shape[0]), int(frac*float(num_Features.shape[0]))) \n",
    "    noise_data_num_x = num_Features[index, :]\n",
    "    noise_data_cat_x = cat_Features[index, :]\n",
    "    noise_data_y = np.array(labels[index])\n",
    "    \n",
    "    \n",
    "    #noise for numerical data\n",
    "    ## get description\n",
    "    noise_data_num_x = pd.DataFrame(noise_data_num_x)\n",
    "    desc = noise_data_num_x.describe()\n",
    "    #print(desc)\n",
    "    desc = np.array(desc)\n",
    "    noise_data_num_x = np.array(noise_data_num_x)\n",
    "    # pick standard dev from description for each column \n",
    "    stds = desc[3, :]\n",
    "    for i in range(len(noise_data_num_x)):                           #iterate over rows\n",
    "        for j, std in enumerate(stds):                           #iterate over each column\n",
    "            w = random.uniform(-std,std)\n",
    "            noise_data_num_x[i, j] = noise_data_num_x[i, j] + w          #add random num from (-std, std) to existing data\n",
    "    data_num_x = np.vstack((num_Features, noise_data_num_x))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###noise for categorical data\n",
    "    #print(labels.shape, noise_data_y.shape)\n",
    "    noise_data_cat_x_pd = pd.DataFrame(noise_data_cat_x)\n",
    "    cat_Features_pd = pd.DataFrame(cat_Features)\n",
    "    for i in range(len(noise_data_cat_x)):\n",
    "        for j, col in enumerate(cat_Features_pd.columns):\n",
    "            unique = np.array(cat_Features_pd[col].unique())\n",
    "            #print(cat_Features_pd[col].value_counts(), unique, unique.dtype, len(unique))\n",
    "            w = randint(0,len(unique) - 1)\n",
    "            while True:\n",
    "                if unique[w] == noise_data_cat_x[i, j]:\n",
    "                    w = randint(0, len(unique) - 1)\n",
    "                else:\n",
    "                    break;\n",
    "            #print(noise_data_cat_x[i, j])\n",
    "            noise_data_cat_x[i, j] = unique[w]\n",
    "            #print(noise_data_cat_x[i, j])\n",
    "    #print(noise_data_cat_x)\n",
    "    #print(noise_data_cat_x.describe())\n",
    "    data_cat_x = np.vstack((cat_Features, noise_data_cat_x))\n",
    "    data_y = np.vstack((labels, noise_data_y))\n",
    "    data_x = np.column_stack((data_num_x, data_cat_x))\n",
    "    data_noise = np.column_stack((data_x, data_y))\n",
    "    data_noise = pd.DataFrame(data_noise)\n",
    "    #print(data_noise.shape)\n",
    "    df = shuffle(data_noise)\n",
    "    df = df.sample(n = 30162)\n",
    "    data = pd.DataFrame(df.values, columns = ['age', 'fnlwgt', 'education-num',\n",
    "       'capital-gain', 'capital-loss', 'hours-per-week', 'workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex',\n",
    "       'native_country', 'salary'])\n",
    "    data_proc = modify_dataset(data)\n",
    "    return data_proc\n",
    "#df = intr_noise_and_preprocess(num_Features1, cat_Features1, labels1, noise)\n",
    "\n",
    "#\n",
    "def naive_bayes(Features, labels):\n",
    "    labels = list(labels)\n",
    "    clf=GaussianNB()\n",
    "    acc = cross_val_score(clf, Features, labels, cv = 10, scoring = 'accuracy')\n",
    "    pr = cross_val_score(clf, Features, labels, cv = 10, scoring = 'precision')\n",
    "    rc = cross_val_score(clf, Features, labels, cv = 10,scoring = 'recall')\n",
    "    f1 = cross_val_score(clf, Features, labels, cv = 10, scoring = 'f1')\n",
    "\n",
    "    #clf.fit(x_train, y_train)\n",
    "    #y_hat_p = clf.predict_proba(x_test)  #score model based on threshold\n",
    "    #y_hat = score_model(y_hat_p, 0.5)\n",
    "    return acc, pr, rc, f1\n",
    "\n",
    "\n",
    "def random_forest_classifier(Features, labels):\n",
    "    labels = list(labels)\n",
    "    clf = RandomForestClassifier(bootstrap= True, max_depth = 100, n_estimators = 50)\n",
    "   \n",
    "    #param_grid = {'bootstrap': [True],\n",
    "    #    'max_depth': [50, 75, 100],\n",
    "    #    'max_features': [2, 3],\n",
    "    #    'min_samples_leaf': [3, 4, 5],\n",
    "    #    'min_samples_split': [8, 10, 12],\n",
    "    #    'n_estimators': [10, 30, 50]}\n",
    "    #gridsearch = GridSearchCV(estimator = clf, param_grid=param_grid, cv = 5, n_jobs = -1, verbose = 2)\n",
    "    #gridsearch.fit(Features, labels)\n",
    "    #print(gridsearch.best_params_)\n",
    "    #print(\"stop\")\n",
    "   \n",
    "    acc = cross_val_score(clf, Features, labels, cv = 10, scoring = 'accuracy')\n",
    "    pr = cross_val_score(clf, Features, labels, cv = 10, scoring = 'precision')\n",
    "    rc = cross_val_score(clf, Features, labels, cv = 10,scoring = 'recall')\n",
    "    f1 = cross_val_score(clf, Features, labels, cv = 10, scoring = 'f1')\n",
    "\n",
    "    #clf.fit(x_train, y_train)\n",
    "    #y_hat_p = clf.predict_proba(x_test)  #score model based on threshold\n",
    "    #y_hat = score_model(y_hat_p, 0.5)\n",
    "    return acc, pr, rc, f1\n",
    "\n",
    "\n",
    "#apply logistic\n",
    "def logistic_regression(Features, labels):\n",
    "    labels = list(labels)\n",
    "   \n",
    "    \n",
    "    clf=LogisticRegression(class_weight='balanced', C = 100, penalty = 'l1')\n",
    "    #param_grid = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "    #gridsearch = GridSearchCV(clf, param_grid, cv = 10)\n",
    "    #gridsearch.fit(Features, labels)\n",
    "    #print(gridsearch.best_params_)\n",
    "    \n",
    "    acc = cross_val_score(clf, Features, labels, cv = 10, scoring = 'accuracy')\n",
    "    pr = cross_val_score(clf, Features, labels, cv = 10, scoring = 'precision')\n",
    "    rc = cross_val_score(clf, Features, labels, cv = 10,scoring = 'recall')\n",
    "    f1 = cross_val_score(clf, Features, labels, cv = 10, scoring = 'f1')\n",
    "\n",
    "    #clf.fit(x_train, y_train)\n",
    "    #y_hat_p = clf.predict_proba(x_test)  #score model based on threshold\n",
    "    #y_hat = score_model(y_hat_p, 0.5)\n",
    "    return acc, pr, rc, f1\n",
    "\n",
    "def calc_npv(y_true, y_pred):\n",
    "    cfmat = sklm.confusion_matrix(y_true, y_pred)\n",
    "    metrics = sklm.precision_recall_fscore_support(y_true, y_pred)\n",
    "    print(\"                     Predicted Positive        Predicted Negative\")\n",
    "    print(\"Actually Positive    %6d\" %cfmat[0][0] + \"                  %6d\" %cfmat[0][1])\n",
    "    print(\"Actually Negative    %6d\" %cfmat[1][0] + \"                  %6d\" %cfmat[1][1])\n",
    "    print(\"\")\n",
    "    #print(\"Accuracy: \" + str(sklm.accuracy_score(y_true, y_predicted)))\n",
    "    #print(\"\")\n",
    "    print(\"            Positive       Negative\")\n",
    "    print(\"Num Cases:  %6f\"%metrics[3][0] + \"          %6.2f\"%metrics[3][1])\n",
    "    print(\"precision:  %6.2f\"%metrics[0][0] + \"          %6.2f\"%metrics[0][1])\n",
    "    print(\"Recall:     %6.2f\"%metrics[1][0] + \"          %6.2f\"%metrics[1][1])\n",
    "    return metrics[1][1]\n",
    "def calc_specificity(y_true, y_pred):\n",
    "    cfmat = sklm.confusion_matrix(y_true, y_pred)\n",
    "    metrics = sklm.precision_recall_fscore_support(y_true, y_pred)\n",
    "    print(\"                     Predicted Positive        Predicted Negative\")\n",
    "    print(\"Actually Positive    %6d\" %cfmat[0][0] + \"                  %6d\" %cfmat[0][1])\n",
    "    print(\"Actually Negative    %6d\" %cfmat[1][0] + \"                  %6d\" %cfmat[1][1])\n",
    "    print(\"\")\n",
    "    #print(\"Accuracy: \" + str(sklm.accuracy_score(y_true, y_predicted)))\n",
    "    #print(\"\")\n",
    "    print(\"            Positive       Negative\")\n",
    "    print(\"Num Cases:  %6f\"%metrics[3][0] + \"          %6.2f\"%metrics[3][1])\n",
    "    print(\"precision:  %6.2f\"%metrics[0][0] + \"          %6.2f\"%metrics[0][1])\n",
    "    print(\"Recall:     %6.2f\"%metrics[1][0] + \"          %6.2f\"%metrics[1][1])\n",
    "    print(\"Specificity %.2f\" %metrics[0][1] + \" npv %.2f\" %metrics[1][1])\n",
    "    print(\"\")\n",
    "    return metrics[0][1]\n",
    "\n",
    "print(\"enter a number for the algorithms: \")\n",
    "print(\"1 - for logistic regression\")\n",
    "print(\"2 - for naive bayes classification\")\n",
    "print(\"3 or any other number - for random forest classifier\")\n",
    "choice=int(input())\n",
    "for i, noise in enumerate([0, 0.1, 0.3, 0.5, 0.7, 0.9]):\n",
    "    #df1 = df\n",
    "    df1 = intr_noise_and_preprocess(num_Features1, cat_Features1, labels1, noise)\n",
    "    labels = np.ravel(df1['salary'])\n",
    "    print(labels.shape)\n",
    "    df1 = df1.drop(['salary'], axis = 1)  #drop salary feature\n",
    "    #print(df.head())\n",
    "    \n",
    "    Features = np.array(df1)\n",
    "    print(Features.shape)\n",
    "    #split data randomly into test and train\n",
    "\n",
    "    nr.seed(9988+i)\n",
    "    #choice = 1\n",
    "    if choice == 1:\n",
    "        print (\"logistic regression\")\n",
    "        acc, pr, rc, f1 = logistic_regression(Features, labels)\n",
    "    if choice == 2:\n",
    "        print(\"naive bayes\")\n",
    "        acc, pr, rc, f1 = naive_bayes(Features, labels)\n",
    "    if choice == 3:\n",
    "        print(\"random forest\")\n",
    "        acc, pr, rc, f1 = random_forest_classifier(Features, labels)\n",
    "    print(\"For noise level %.2f %%: \"%(noise*100))\n",
    "    print(\"accuracy = %.2f\" %np.mean(acc))\n",
    "    print(\"recall = %.2f\" %np.mean(rc))\n",
    "    print(\"precision = %.2f\" %np.mean(pr))\n",
    "    print(\"f1 = %.2f\" %np.mean(f1))\n",
    "    #p, r = print_metrics(y_test, y_hat)\n",
    "    if i == 0:\n",
    "        plt.plot(noise, np.mean(acc), 'ro', label = 'Accuracy')\n",
    "        plt.plot(noise, np.mean(rc), 'bo', label = 'Recall')\n",
    "        plt.plot(noise, np.mean(pr), 'go', label = 'Pricision')\n",
    "        plt.plot(noise, np.mean(f1), 'orange', marker = 'o', label = 'F1 score')\n",
    "    else:\n",
    "        plt.plot(noise, np.mean(acc), 'ro')\n",
    "        plt.plot(noise, np.mean(rc), 'bo')\n",
    "        plt.plot(noise, np.mean(pr), 'go')\n",
    "        plt.plot(noise, np.mean(f1), color='orange', marker='o')\n",
    "plt.xlabel('Noise')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('Noise vs Metric')\n",
    "#plt.title('Noise vs Metric for Random Forest classifier')\n",
    "#plt.title('Noise vs Metric for naive_bayes classifier')\n",
    "#plt.xlim((0,1))\n",
    "plt.ylim((0,1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
