{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krishna\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For noise level % 0.00: \n",
      "                     Predicted Positive        Predicted Negative\n",
      "Actually Positive     85294                      15\n",
      "Actually Negative        46                      88\n",
      "\n",
      "            Positive       Negative\n",
      "Num Cases:  85309.000000          134.00\n",
      "precision:    1.00            0.85\n",
      "Recall:       1.00            0.66\n",
      "\n",
      "For noise level % 0.20: \n",
      "                     Predicted Positive        Predicted Negative\n",
      "Actually Positive     85273                      15\n",
      "Actually Negative        62                      93\n",
      "\n",
      "            Positive       Negative\n",
      "Num Cases:  85288.000000          155.00\n",
      "precision:    1.00            0.86\n",
      "Recall:       1.00            0.60\n",
      "\n",
      "For noise level % 0.30: \n",
      "                     Predicted Positive        Predicted Negative\n",
      "Actually Positive     85296                       9\n",
      "Actually Negative        64                      74\n",
      "\n",
      "            Positive       Negative\n",
      "Num Cases:  85305.000000          138.00\n",
      "precision:    1.00            0.89\n",
      "Recall:       1.00            0.54\n",
      "\n",
      "For noise level % 0.60: \n",
      "                     Predicted Positive        Predicted Negative\n",
      "Actually Positive     85276                      10\n",
      "Actually Negative        77                      80\n",
      "\n",
      "            Positive       Negative\n",
      "Num Cases:  85286.000000          157.00\n",
      "precision:    1.00            0.89\n",
      "Recall:       1.00            0.51\n",
      "\n",
      "For noise level % 0.90: \n",
      "                     Predicted Positive        Predicted Negative\n",
      "Actually Positive     85287                      14\n",
      "Actually Negative        68                      74\n",
      "\n",
      "            Positive       Negative\n",
      "Num Cases:  85301.000000          142.00\n",
      "precision:    1.00            0.84\n",
      "Recall:       1.00            0.52\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import numpy.random as nr\n",
    "import random\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#read data\n",
    "data1 = pd.read_csv('creditcard.csv')\n",
    "\n",
    "#scale data, last and first column of features is only data unscaled\n",
    "#print(data.columns)\n",
    "\n",
    "#take features\n",
    "Features1 = np.array(data1[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']])\n",
    "\n",
    "#scale amount column\n",
    "col = Features1[:, -1]\n",
    "scaler = preprocessing.StandardScaler().fit(col.reshape(-1,1))\n",
    "col = scaler.transform(col.reshape(-1,1))\n",
    "col = np.ravel(col)\n",
    "Features1[:, -1] = col\n",
    "\n",
    "#take labels\n",
    "labels1 = np.array(data1[['Class']])\n",
    "\n",
    "# Introduce Noise\n",
    "def intr_noise(Features, labels, frac):\n",
    "    nr.seed(1234)\n",
    "    index = range(Features.shape[0])\n",
    "    #print(Features.shape[0])\n",
    "    index = random.sample(range(Features.shape[0]), int(frac*float(Features.shape[0]))) \n",
    "    noise_data_x = Features[index, :]\n",
    "    noise_data_y = np.array(labels[index])\n",
    "    ## get description\n",
    "    noise_data_x = pd.DataFrame(noise_data_x)\n",
    "    desc = noise_data_x.describe()\n",
    "    desc = np.array(desc)\n",
    "    noise_data_x = np.array(noise_data_x)\n",
    "    # pick standard dev from description for each column \n",
    "    stds = desc[2,:]\n",
    "    for i in range(len(noise_data_x)):                           #iterate over rows\n",
    "        for j, std in enumerate(stds):                           #iterate over each column\n",
    "            w = random.uniform(-std,std)\n",
    "            noise_data_x[i, j] = noise_data_x[i, j] + 2*w          #add random num from (-std, std) to existing data\n",
    "    noise_data_y\n",
    "    data_x = np.vstack((Features, noise_data_x))\n",
    "    #print(labels.shape, noise_data_y.shape)\n",
    "    data_y = np.vstack((labels, noise_data_y))\n",
    "    data_noise = np.column_stack((data_x, data_y))\n",
    "    data_noise = pd.DataFrame(data_noise)\n",
    "    #print(data_noise.shape)\n",
    "    df = shuffle(data_noise)\n",
    "    df = df.sample(n = 284807)\n",
    "    #print(df.shape)\n",
    "    return df\n",
    "\n",
    "def score_model(y_p, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in y_p[:, 1]])\n",
    "\n",
    "#apply logistic\n",
    "def logistic_regression(x_train, x_test, y_train):\n",
    "    clf=LogisticRegression(fit_intercept=True)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_hat_p = clf.predict_proba(x_test)  #score model based on threshold\n",
    "    y_hat = score_model(y_hat_p, 0.5)\n",
    "    return y_hat_p, y_hat\n",
    "\n",
    "#apply naive bayes\n",
    "def naive_bayes(x_train, x_test, y_train):\n",
    "    clf=GaussianNB()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_hat_p = clf.predict_proba(x_test)  #score model based on threshold\n",
    "    y_hat = score_model(y_hat_p, 0.5)\n",
    "    return y_hat_p, y_hat\n",
    "\n",
    "#random forest\n",
    "def random_forest_classifier(x_train, x_test, y_train):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_hat_p = clf.predict_proba(x_test)  #score model based on threshold\n",
    "    y_hat = score_model(y_hat_p, 0.5)\n",
    "    return y_hat_p, y_hat\n",
    "\n",
    "#print metrics\n",
    "def print_metrics(y_true, y_predicted):\n",
    "    metrics = sklm.precision_recall_fscore_support(y_true, y_predicted)\n",
    "    cfmat = sklm.confusion_matrix(y_true, y_predicted)\n",
    "    print(\"                     Predicted Positive        Predicted Negative\")\n",
    "    print(\"Actually Positive    %6d\" %cfmat[0][0] + \"                  %6d\" %cfmat[0][1])\n",
    "    print(\"Actually Negative    %6d\" %cfmat[1][0] + \"                  %6d\" %cfmat[1][1])\n",
    "    print(\"\")\n",
    "    #print(\"Accuracy: \" + str(sklm.accuracy_score(y_true, y_predicted)))\n",
    "    #print(\"\")\n",
    "    print(\"            Positive       Negative\")\n",
    "    print(\"Num Cases:  %6f\"%metrics[3][0] + \"          %6.2f\"%metrics[3][1]) \n",
    "    print(\"precision:  %6.2f\"%metrics[0][0] + \"          %6.2f\"%metrics[0][1])\n",
    "    print(\"Recall:     %6.2f\"%metrics[1][0] + \"          %6.2f\"%metrics[1][1])\n",
    "    #print(\"fscore:     %6.2f\"%metrics[2][0] + \"          %6.2f\"%metrics[2][1])\n",
    "    print(\"\")\n",
    "    #mp = (metrics[0][0] + metrics[0][1]) / 2\n",
    "    #mr = (metrics[1][0] + metrics[1][1]) / 2\n",
    "    #f1 = (2 * mp * mr) / (mp + mr)\n",
    "    #ci = float(float(cfmat[1][1])/float(cfmat[1][1] + cfmat[1][0]))\n",
    "    #print(\"Correctly identified fraud:  %6.2f\"%ci)\n",
    "    #print(\"Average Precision:           %6.2f\"%mp)\n",
    "    #print(\"Average Recall:              %6.2f\"%mr)\n",
    "    #print(\"F1 Score:                    %6.2f\"%f1)\n",
    "    #cohen_score = cohen_kappa_score(y_true, y_predicted)\n",
    "    #print(\"Cohen kappa:                 %6.2f\"%cohen_score)\n",
    "    return metrics[0][1], metrics[1][1]\n",
    "#[0,0.2,0.3,0.6,0.9]\n",
    "for i, noise in enumerate([0,0.2,0.3,0.6,0.9]):\n",
    "    df = intr_noise(Features1, labels1, noise)\n",
    "    #print(df.shape, df.columns, df.tail())\n",
    "    labels = np.array(df[29])\n",
    "    df = df.drop((29), axis = 1)  #drop Class feature\n",
    "    Features = np.array(df)\n",
    "    #split data randomly into test and train\n",
    "\n",
    "    nr.seed(9988)\n",
    "    index = range(df.shape[0])\n",
    "    index = ms.train_test_split(index,test_size=0.3)\n",
    "    x_train = np.array(Features[index[0], :])\n",
    "    y_train = np.ravel(labels[index[0]])\n",
    "    x_test = np.array(Features[index[1], :])\n",
    "    y_test = np.ravel(labels[index[1]])\n",
    "    #print (y_test)\n",
    "    #print (y_train.shape)\n",
    "    y_hat_p, y_hat = logistic_regression(x_train, x_test, y_train)\n",
    "    #y_hat_p, y_hat = naive_bayes(x_train, x_test, y_train)\n",
    "    #y_hat_p, y_hat = random_forest_classifier(x_train, x_test, y_train)\n",
    "    print(\"For noise level %% %0.2f: \"%noise)\n",
    "    p, r = print_metrics(y_test, y_hat)\n",
    "    if i == 0:\n",
    "        plt.plot(noise, p, 'bo', label = 'precision for negative cases')\n",
    "        plt.plot(noise, r, 'ro', label = 'recall for negative cases')\n",
    "        #plt.plot(noise, f, 'ro', label = 'f1score for negative cases')\n",
    "    else:\n",
    "        plt.plot(noise, p, 'bo')\n",
    "        plt.plot(noise, r, 'ro')\n",
    "        #plt.plot(noise, f, 'ro')\n",
    "    \n",
    "plt.xlabel('Noise')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('Noise vs Metric for logistic regression')\n",
    "#plt.title('Noise vs Metric for Random Forest classifier')\n",
    "#plt.title('Noise vs Metric for naive_bayes classifier')\n",
    "#plt.xlim((0,1))\n",
    "plt.ylim((0,1))\n",
    "plt.legend()\n",
    "plt.savefig('logistic.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
