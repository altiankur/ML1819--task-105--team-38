{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as sklm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import numpy.random as nr\n",
    "import random\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "data1 = pd.read_csv('creditcard.csv')\n",
    "\n",
    "#scale data, last and first column of features is only data unscaled\n",
    "#print(data.columns)\n",
    "\n",
    "#take features\n",
    "Features1 = np.array(data1[['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']])\n",
    "\n",
    "#scale amount column\n",
    "col = Features1[:, -1]\n",
    "scaler = preprocessing.StandardScaler().fit(col.reshape(-1,1))\n",
    "col = scaler.transform(col.reshape(-1,1))\n",
    "col = np.ravel(col)\n",
    "Features1[:, -1] = col\n",
    "\n",
    "#take labels\n",
    "labels1 = np.array(data1[['Class']])\n",
    "\n",
    "# Introduce Noise\n",
    "def intr_noise(Features, labels, frac):\n",
    "    nr.seed(1234)\n",
    "    index = range(Features.shape[0])\n",
    "    #print(Features.shape[0])\n",
    "    index = random.sample(range(Features.shape[0]), int(frac*float(Features.shape[0]))) \n",
    "    noise_data_x = Features[index, :]\n",
    "    noise_data_y = np.array(labels[index])\n",
    "    ## get description\n",
    "    noise_data_x = pd.DataFrame(noise_data_x)\n",
    "    desc = noise_data_x.describe()\n",
    "    desc = np.array(desc)\n",
    "    noise_data_x = np.array(noise_data_x)\n",
    "    # pick standard dev from description for each column \n",
    "    stds = desc[2,:]\n",
    "    for i in range(len(noise_data_x)):                           #iterate over rows\n",
    "        for j, std in enumerate(stds):                           #iterate over each column\n",
    "            w = random.uniform(-std,std)\n",
    "            noise_data_x[i, j] = noise_data_x[i, j] + 2*w          #add random num from (-std, std) to existing data\n",
    "    noise_data_y\n",
    "    data_x = np.vstack((Features, noise_data_x))\n",
    "    #print(labels.shape, noise_data_y.shape)\n",
    "    data_y = np.vstack((labels, noise_data_y))\n",
    "    data_noise = np.column_stack((data_x, data_y))\n",
    "    data_noise = pd.DataFrame(data_noise)\n",
    "    #print(data_noise.shape)\n",
    "    df = shuffle(data_noise)\n",
    "    #df = df.sample(n = 284807)\n",
    "    #print(df.shape)\n",
    "    return df\n",
    "\n",
    "def score_model(y_p, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in y_p[:, 1]])\n",
    "\n",
    "#apply logistic\n",
    "def logistic_regression(x_train, x_test, y_train):\n",
    "    clf=LogisticRegression(fit_intercept=True)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_hat_p = clf.predict_proba(x_test)  #score model based on threshold\n",
    "    y_hat = score_model(y_hat_p, 0.25)\n",
    "    return y_hat_p, y_hat\n",
    "\n",
    "#apply svm\n",
    "def svm(x_train, x_test, y_train):\n",
    "    svclassifier = SVC(kernel='linear', probability=True)\n",
    "    svclassifier.fit(x_train, y_train)\n",
    "    y_hat_p = svclassifier.predict_proba(x_test)  #score model based on threshold\n",
    "    y_hat = score_model(y_hat_p, 0.25)\n",
    "    return y_hat_p, y_hat\n",
    "\n",
    "#apply naive bayes\n",
    "def naive_bayes(x_train, x_test, y_train):\n",
    "    clf=GaussianNB()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_hat_p = clf.predict_proba(x_test)  #score model based on threshold\n",
    "    y_hat = score_model(y_hat_p, 0.25)\n",
    "    return y_hat_p, y_hat\n",
    "\n",
    "#print metrics\n",
    "def print_metrics(y_true, y_predicted):\n",
    "    metrics = sklm.precision_recall_fscore_support(y_true, y_predicted)\n",
    "    cfmat = sklm.confusion_matrix(y_true, y_predicted)\n",
    "    print(\"                     Predicted Positive        Predicted Negative\")\n",
    "    print(\"Actually Positive    %6d\" %cfmat[0][0] + \"                  %6d\" %cfmat[0][1])\n",
    "    print(\"Actually Negative    %6d\" %cfmat[1][0] + \"                  %6d\" %cfmat[1][1])\n",
    "    print(\"\")\n",
    "    print(\"Accuracy: \" + str(sklm.accuracy_score(y_true, y_predicted)))\n",
    "    print(\"\")\n",
    "    print(\"            Positive       Negative\")\n",
    "    print(\"Num Cases:  %6f\"%metrics[3][0] + \"          %6.2f\"%metrics[3][1]) \n",
    "    print(\"precision:  %6.2f\"%metrics[0][0] + \"          %6.2f\"%metrics[0][1])\n",
    "    print(\"Recall:     %6.2f\"%metrics[1][0] + \"          %6.2f\"%metrics[1][1])\n",
    "    print(\"fscore:     %6.2f\"%metrics[2][0] + \"          %6.2f\"%metrics[2][1])\n",
    "    print(\"\")\n",
    "    mp = (metrics[0][0] + metrics[0][1]) / 2\n",
    "    mr = (metrics[1][0] + metrics[1][1]) / 2\n",
    "    f1 = (2 * mp * mr) / (mp + mr)\n",
    "    ci = float(float(cfmat[1][1])/float(cfmat[1][1] + cfmat[1][0]))\n",
    "    print(\"Correctly identified fraud:  %6.2f\"%ci)\n",
    "    print(\"Average Precision:           %6.2f\"%mp)\n",
    "    print(\"Average Recall:              %6.2f\"%mr)\n",
    "    print(\"F1 Score:                    %6.2f\"%f1)\n",
    "    return metrics[0][1], metrics[1][1], metrics[2][1]\n",
    "\n",
    "for i, noise in enumerate([0,0.4, 0.80]):\n",
    "    df = intr_noise(Features1, labels1, noise)\n",
    "    #print(df.shape, df.columns, df.tail())\n",
    "    labels = np.array(df[29])\n",
    "    df = df.drop((29), axis = 1)  #drop Class feature\n",
    "    Features = np.array(df)\n",
    "    #split data randomly into test and train\n",
    "\n",
    "    nr.seed(9988)\n",
    "    index = range(df.shape[0])\n",
    "    index = ms.train_test_split(index,test_size=0.3)\n",
    "    x_train = np.array(Features[index[0], :])\n",
    "    y_train = np.ravel(labels[index[0]])\n",
    "    x_test = np.array(Features[index[1], :])\n",
    "    y_test = np.ravel(labels[index[1]])\n",
    "    #print (y_test)\n",
    "    #print (y_train.shape)\n",
    "    y_hat_p, y_hat = svm(x_train, x_test, y_train)\n",
    "    #y_hat_p, y_hat = naive_bayes(x_train, x_test, y_train)\n",
    "    p, r, f = print_metrics(y_test, y_hat)\n",
    "    if i == 0:\n",
    "        plt.plot(noise, p, 'bo', label = 'precission for negative cases')\n",
    "        plt.plot(noise, r, 'go', label = 'recall for negative cases')\n",
    "        plt.plot(noise, f, 'ro', label = 'f1score for negative cases')\n",
    "    else:\n",
    "        plt.plot(noise, p, 'bo')\n",
    "        plt.plot(noise, r, 'go')\n",
    "        plt.plot(noise, f, 'ro')\n",
    "    \n",
    "plt.xlabel('Noise')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
